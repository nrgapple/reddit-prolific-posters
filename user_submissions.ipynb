{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out the users that post the most in a set of subreddits\n",
    "\n",
    "edit the `sub_names` var to add/remove subreddits from the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 'all', 'news', 'interestingasfuck', 'whitePeopleTwitter', 'worldnews', 'todayilearned', 'BlackPeopleTwitter', 'PoliticalHumor', 'MadeMeSmile', 'memes', 'pics', 'antiwork', 'PublicFreakout']\n",
      "Total submissions: 2800\n",
      "Number of unique authors: 1866\n",
      "\n",
      "Quartiles:\n",
      "author\n",
      "25%     103\n",
      "50%     368\n",
      "75%     697\n",
      "100%    698\n",
      "Name: author, dtype: int64\n",
      "\n",
      "Top 5 authors:\n",
      "                  Count   Percent\n",
      "Author                           \n",
      "DaFunkJunkie         41  1.470061\n",
      "pietradolce          27  0.968089\n",
      "CrooklynKnight       19  0.681248\n",
      "Limitless_yt89       16  0.573682\n",
      "dilettantedebrah     15  0.537827\n",
      "\n",
      "======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "##### vars #####\n",
    "sub_names = ['politics', 'all', 'news', 'interestingasfuck', 'whitePeopleTwitter', 'worldnews', 'todayilearned', 'BlackPeopleTwitter', 'PoliticalHumor', 'MadeMeSmile', 'memes', 'pics', 'antiwork', 'PublicFreakout']\n",
    "################\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv('client_id'),\n",
    "    client_secret=os.getenv('client_secret'),\n",
    "    user_agent=\"submissions comments\",\n",
    "    username=os.getenv('username'),\n",
    ")\n",
    "\n",
    "def serialize_reddit(s): \n",
    "    return {\n",
    "        \"author\": s.author,\n",
    "        \"created_utc\": s.created_utc,\n",
    "    }\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "submissions = list(flatten(reddit.subreddit(s).top(time_filter='month',limit=200) for s in sub_names))\n",
    "df = pd.DataFrame([serialize_reddit(s) for s in submissions])\n",
    "df['created_utc'] = pd.to_datetime(df.created_utc.values, unit='s', utc=True)\n",
    "\n",
    "print(sub_names)\n",
    "\n",
    "ndf = df.query('author != \"None\"')\n",
    "print('Total submissions:', len(ndf))\n",
    "\n",
    "print('Number of unique authors:', ndf.author.nunique())\n",
    "\n",
    "csum = ndf.author.value_counts(1).cumsum()\n",
    "\n",
    "bins = pd.cut(csum, [0., 0.25, 0.5, 0.75, 1.], labels=['25%','50%','75%','100%'])\n",
    "\n",
    "print('\\nQuartiles:')\n",
    "print(csum.groupby(bins).size())\n",
    "\n",
    "print('\\nTop 5 authors:')\n",
    "topa = pd.concat([ndf.author.value_counts().head(), ndf.author.value_counts(1).head()*100],axis=1)\n",
    "topa.index.name = 'Author'\n",
    "topa.columns = ('Count', 'Percent')\n",
    "print(topa)\n",
    "print('\\n======\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('reddit-users-block-Rxij7APa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d7ecf6afba16f901927fc1162f07b9a8a7420dc9fcba892830f880204cb1b7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
